{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect word frequency from Microsoft N-Gram service\n",
    "============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import MicrosoftNgram as mn\n",
    "from time import sleep\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category_id', 'description', 'count']\n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "inputFile = 'data/cat_desc_wn.csv'\n",
    "headers = None\n",
    "descCnt = Counter()\n",
    "with open(inputFile) as fin:\n",
    "    r = csv.reader(fin)\n",
    "    for row in r:\n",
    "        if headers is None:\n",
    "            headers = row\n",
    "            print headers\n",
    "        else:\n",
    "            descCnt[row[1]] += int(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3058\n"
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "queryList = [w for w, v in descCnt.most_common() if v >= threshold]\n",
    "print len(queryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bing-body/2013-12/3\n",
      "-6.43\n",
      "-4.57\n"
     ]
    }
   ],
   "source": [
    "token = 'df5dc471-6880-4e5c-86bf-0049f44df1e8'\n",
    "lookup = mn.LookupService(token)\n",
    "print lookup.GetModel()\n",
    "print lookup.GetJointProbability('class room')\n",
    "print lookup.GetJointProbability('classroom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 animal -4.057\n",
      "200 bathtub -5.439\n",
      "300 fire -3.733\n",
      "400 pier -5.186\n",
      "500 washroom -6.026\n",
      "600 control_center -5.912\n",
      "700 showcase -4.806\n",
      "800 engine -3.795\n",
      "900 ballpark -5.98\n",
      "1000 post -3.111\n",
      "1100 chef -4.447\n",
      "1200 workman -5.849\n",
      "1300 bread -4.502\n",
      "1400 dance_hall -6.609\n",
      "1500 airport_terminal -6.433\n",
      "1600 sand_trap -7.211\n",
      "1700 solar_energy -5.437\n",
      "1800 sandpit -6.966\n",
      "1900 lava -5.414\n",
      "2000 marching -5.442\n",
      "2100 batting -5.2\n",
      "2200 turtle -5.121\n",
      "2300 award -4.162\n",
      "2400 skater -5.717\n",
      "2500 rome -4.698\n",
      "2600 item -3.334\n",
      "2700 field_work -6.286\n",
      "2800 location -3.328\n",
      "2900 handiwork -6.649\n",
      "3000 pop -4.237\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "wordLog10Freq = {}\n",
    "wordLog10FreqFile = 'data/MsrWordLog10Freq.csv'\n",
    "i = 0\n",
    "while len(wordLog10Freq) < len(queryList):\n",
    "    w = queryList[i]\n",
    "    i = (i+1) % len(queryList)\n",
    "    if w not in wordLog10Freq:\n",
    "        try:\n",
    "            wordLog10Freq[w] = lookup.GetJointProbability(w.replace('_', ' '))\n",
    "            sleep(0.2)\n",
    "            if len(wordLog10Freq) % 100 == 0:\n",
    "                print len(wordLog10Freq), w, wordLog10Freq[w]\n",
    "        except:\n",
    "            sleep(10)\n",
    "print set(wordLog10Freq.keys()) == set(queryList)\n",
    "with open(wordLog10FreqFile, 'w') as fout:\n",
    "    fw = csv.writer(fout)\n",
    "    fw.writerow(['description', 'log10JointProb'])\n",
    "    for w in queryList:\n",
    "        fw.writerow([w, str(wordLog10Freq[w])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child's_room\n",
      "merry-go-round\n",
      "farmer's_market\n",
      "baby's_room\n",
      "child's_play\n"
     ]
    }
   ],
   "source": [
    "for w in queryList:\n",
    "    if ',' in w:\n",
    "        print 'ERROR', w\n",
    "    elif any(c not in string.ascii_lowercase and c != ' ' and c != ',' for c in w.replace('_', ' ')):\n",
    "        print w\n",
    "googleNGramResp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Google N-Gram\n",
    "import urllib\n",
    "import urllib2\n",
    "import json\n",
    "baseURL='https://books.google.com/ngrams/graph?case_insensitive=on&year_start=1990&year_end=2008&corpus=15&smoothing=20&content='\n",
    "discardChar='&.,'\n",
    "dataLine = 'var data = ['\n",
    "handleAposHTML = lambda s: s.replace('&#39;', \"'\")\n",
    "def fetchGoogleNGram(wLst):\n",
    "    wLst2 = [w.translate(None, discardChar).replace('_', ' ') for w in wLst]\n",
    "    wParam = urllib.quote_plus(','.join(wLst2))\n",
    "    resp = urllib2.urlopen(baseURL + wParam, timeout=10).read().split('\\n')\n",
    "    dataLines = [s for s in resp if s.strip().startswith(dataLine)]\n",
    "    if len(dataLines) != 1:\n",
    "        raise RuntimeError('Confused by response: ' + str(resp))\n",
    "    data = dataLines[0].strip()[len(dataLine) - 1:-1]\n",
    "    if len(data.strip()) == 0:\n",
    "        data = []\n",
    "    else:\n",
    "        data = json.loads(data)\n",
    "    ret = [0.0] * len(wLst)\n",
    "    for d in data:\n",
    "        if len(d) == 0:\n",
    "            continue\n",
    "        if d['parent'] != '':\n",
    "            continue\n",
    "        matching = [w for w in wLst2 if handleAposHTML(d['ngram']).replace(' ', '').lower()\n",
    "                    .startswith(w.replace(' ', '').lower())]\n",
    "        if len(matching) == 0:\n",
    "            continue\n",
    "        if len(matching) > 1:\n",
    "            t = max(matching, key=len)\n",
    "            if any(not t.startswith(s) for s in matching):\n",
    "                raise RuntimeError('Confused by response: ' + str(matching)\n",
    "                                   + ' | ' + d['ngram'] + ' | ' + str(dataLines))\n",
    "            else:\n",
    "                matching = [t]\n",
    "        if len(matching) == 1:\n",
    "            ret[wLst2.index(matching[0])] = d['timeseries'][-1]\n",
    "    for i, x in enumerate(ret):\n",
    "        if x == 0.0:\n",
    "            print 'Not Found:', wLst[i], '|', wLst2[i]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "i = 0\n",
    "while len(googleNGramResp) < len(queryList):\n",
    "    wLst = []\n",
    "    while len(wLst) < min(batchSize, len(queryList) - len(googleNGramResp)):\n",
    "        if queryList[i] not in googleNGramResp and queryList[i] not in wLst:\n",
    "            wLst.append(queryList[i])\n",
    "        i = (i + 1) % len(queryList)\n",
    "    resp = None\n",
    "    try:\n",
    "        sleep(1)\n",
    "        resp = fetchGoogleNGram(wLst)\n",
    "    except Exception as e:\n",
    "        sleep(10)\n",
    "        print type(e)\n",
    "        print e\n",
    "    if resp is not None:\n",
    "        for w, x in zip(wLst, resp):\n",
    "            googleNGramResp[w] = x\n",
    "        if len(googleNGramResp) % 10 == 0:\n",
    "            print 'Success', len(googleNGramResp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFile = 'data/GNGramFreq.csv'\n",
    "with open(outputFile, 'w') as fout:\n",
    "    fw = csv.writer(fout)\n",
    "    fw.writerow(['description', 'JointProb'])\n",
    "    for w in queryList:\n",
    "        fw.writerow([w, str(googleNGramResp[w])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in googleNGramResp.keys():\n",
    "    if googleNGramResp[w] == 0:\n",
    "        del googleNGramResp[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wasteyard']\n"
     ]
    }
   ],
   "source": [
    "wLst = []\n",
    "while len(wLst) < min(batchSize, len(queryList) - len(googleNGramResp)):\n",
    "    if queryList[i] not in googleNGramResp and queryList[i] not in wLst:\n",
    "        wLst.append(queryList[i])\n",
    "    i = (i + 1) % len(queryList)\n",
    "print wLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "googleNGramResp['wasteyard'] = 0.0\n",
    "print googleNGramResp['wasteyard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31540497372e-07\n"
     ]
    }
   ],
   "source": [
    "googleNGramResp[\"child's_play\"] = 3.3154049737161905e-07\n",
    "print googleNGramResp[\"child's_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
