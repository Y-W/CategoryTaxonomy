{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling Taxonomy Tree of Categories\n",
    "===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import multiprocessing as mp\n",
    "from math import log\n",
    "from functools import partial\n",
    "import pickle\n",
    "import gzip\n",
    "import csv\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category_id', 'description', 'count']\n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "catDescFile = 'data/cat_desc_wn.csv'\n",
    "catDescHeaders = None\n",
    "descCatCnt = defaultdict(Counter)\n",
    "descCnt = Counter()\n",
    "with open(catDescFile) as fin:\n",
    "    r = csv.reader(fin)\n",
    "    for row in r:\n",
    "        if catDescHeaders is None:\n",
    "            catDescHeaders = row\n",
    "            print catDescHeaders\n",
    "        else:\n",
    "            descCatCnt[row[1]][int(row[0]) - 1] += int(row[-1])\n",
    "            descCnt[row[1]] += int(row[-1])\n",
    "\n",
    "catNameFile = 'data/categoryKey.csv'\n",
    "catName = {}\n",
    "with open(catNameFile) as fin:\n",
    "    r = csv.reader(fin)\n",
    "    for row in r:\n",
    "        catName[int(row[0]) - 1] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load taxonomy tree\n",
    "taxonomyFile = 'model/hcTree1_original.pickle.gz'\n",
    "with gzip.open(taxonomyFile) as fin:\n",
    "    taxoTreeNodes = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917 2917\n",
      "4450878 4450878\n"
     ]
    }
   ],
   "source": [
    "# Take descriptions of occurance >= $threshold$ and normalize distribution\n",
    "threshold = 10\n",
    "descList = [d for d, c in descCnt.most_common() if c >= threshold]\n",
    "print len(descList), len(descCnt)\n",
    "print sum(descCnt[d] for d in descList), sum(descCnt.itervalues())\n",
    "\n",
    "descSet = set(descList)\n",
    "descDist = defaultdict(Counter)\n",
    "for desc, dist in descCatCnt.iteritems():\n",
    "    if desc not in descSet: continue\n",
    "    s = float(sum(dist.itervalues()))\n",
    "    for c, v in dist.iteritems():\n",
    "        descDist[desc][c] += v / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JensenShannonDiv(dist1, dist2):\n",
    "    ans = 0.0\n",
    "    for k in set(dist1.keys()) | set(dist2.keys()):\n",
    "        x = dist1[k] if k in dist1 else 0\n",
    "        y = dist2[k] if k in dist2 else 0\n",
    "        m = (x + y) * 0.5\n",
    "        if x > 0:\n",
    "            ans += x * log(x / m)\n",
    "        if y > 0:\n",
    "            ans += y * log(y / m)\n",
    "    return ans * 0.5\n",
    "\n",
    "def evalMatch(catDist, descDist, desc):\n",
    "    return JensenShannonDiv(catDist, descDist[desc]) - 0.01 * log(descCnt[desc])\n",
    "\n",
    "def matchingResult(catSet, mpPool, topNums=5):\n",
    "    catDist = {c:1.0 / len(catSet) for c in catSet}\n",
    "    mpKernel = partial(evalMatch, catDist, descDist)\n",
    "    vals = mpPool.map(mpKernel, descList)\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build category sets for each node in the taxonomy tree\n",
    "nodeCatSet = []\n",
    "for i, node in enumerate(taxoTreeNodes):\n",
    "    if node[0] == 1:\n",
    "        nodeCatSet.append(set([i]))\n",
    "    else:\n",
    "        nodeCatSet.append(nodeCatSet[node[-3]] | nodeCatSet[node[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing node # 0\n",
      "Processing node # 10\n",
      "Processing node # 20\n",
      "Processing node # 30\n",
      "Processing node # 40\n",
      "Processing node # 50\n",
      "Processing node # 60\n",
      "Processing node # 70\n",
      "Processing node # 80\n",
      "Processing node # 90\n",
      "Processing node # 100\n",
      "Processing node # 110\n",
      "Processing node # 120\n",
      "Processing node # 130\n",
      "Processing node # 140\n",
      "Processing node # 150\n",
      "Processing node # 160\n",
      "Processing node # 170\n",
      "Processing node # 180\n",
      "Processing node # 190\n",
      "Processing node # 200\n",
      "Processing node # 210\n",
      "Processing node # 220\n",
      "Processing node # 230\n",
      "Processing node # 240\n",
      "Processing node # 250\n",
      "Processing node # 260\n",
      "Processing node # 270\n",
      "Processing node # 280\n",
      "Processing node # 290\n",
      "Processing node # 300\n",
      "Processing node # 310\n",
      "Processing node # 320\n",
      "Processing node # 330\n",
      "Processing node # 340\n",
      "Processing node # 350\n",
      "Processing node # 360\n",
      "Processing node # 370\n",
      "Processing node # 380\n",
      "Processing node # 390\n",
      "Processing node # 400\n",
      "Processing node # 410\n",
      "Processing node # 420\n",
      "Processing node # 430\n",
      "Processing node # 440\n",
      "Processing node # 450\n",
      "Processing node # 460\n",
      "Processing node # 470\n",
      "Processing node # 480\n",
      "Processing node # 490\n",
      "Processing node # 500\n",
      "Processing node # 510\n",
      "Processing node # 520\n",
      "Processing node # 530\n",
      "Processing node # 540\n",
      "Processing node # 550\n",
      "Processing node # 560\n",
      "Processing node # 570\n",
      "Processing node # 580\n",
      "Processing node # 590\n",
      "Processing node # 600\n",
      "Processing node # 610\n",
      "Processing node # 620\n",
      "Processing node # 630\n",
      "Processing node # 640\n",
      "Processing node # 650\n",
      "Processing node # 660\n",
      "Processing node # 670\n",
      "Processing node # 680\n",
      "Processing node # 690\n",
      "Processing node # 700\n",
      "Processing node # 710\n",
      "Processing node # 720\n",
      "Processing node # 730\n",
      "Processing node # 740\n",
      "Processing node # 750\n",
      "Processing node # 760\n",
      "Processing node # 770\n",
      "Processing node # 780\n",
      "Processing node # 790\n",
      "Processing node # 800\n",
      "Processing node # 810\n",
      "Processing node # 820\n",
      "Processing node # 830\n",
      "Processing node # 840\n",
      "Processing node # 850\n",
      "Processing node # 860\n",
      "Processing node # 870\n",
      "Processing node # 880\n",
      "Processing node # 890\n",
      "Processing node # 900\n",
      "Processing node # 910\n",
      "Processing node # 920\n",
      "Processing node # 930\n",
      "Processing node # 940\n",
      "Processing node # 950\n",
      "Processing node # 960\n",
      "Processing node # 970\n",
      "Processing node # 980\n",
      "Processing node # 990\n",
      "Processing node # 1000\n",
      "Processing node # 1010\n",
      "Processing node # 1020\n",
      "Processing node # 1030\n",
      "Processing node # 1040\n",
      "Processing node # 1050\n",
      "Processing node # 1060\n",
      "Processing node # 1070\n",
      "Processing node # 1080\n",
      "Processing node # 1090\n",
      "Processing node # 1100\n",
      "Processing node # 1110\n",
      "Processing node # 1120\n",
      "Processing node # 1130\n",
      "Processing node # 1140\n",
      "Processing node # 1150\n",
      "Processing node # 1160\n",
      "Processing node # 1170\n",
      "Processing node # 1180\n",
      "Processing node # 1190\n",
      "Processing node # 1200\n",
      "Processing node # 1210\n",
      "Processing node # 1220\n",
      "Processing node # 1230\n",
      "Processing node # 1240\n",
      "Processing node # 1250\n",
      "Processing node # 1260\n",
      "Processing node # 1270\n",
      "Processing node # 1280\n",
      "Processing node # 1290\n",
      "Processing node # 1300\n",
      "Processing node # 1310\n",
      "Processing node # 1320\n",
      "Processing node # 1330\n",
      "Processing node # 1340\n",
      "Processing node # 1350\n",
      "Processing node # 1360\n",
      "Processing node # 1370\n",
      "Processing node # 1380\n",
      "Processing node # 1390\n",
      "Processing node # 1400\n",
      "Processing node # 1410\n",
      "Processing node # 1420\n",
      "Processing node # 1430\n",
      "Processing node # 1440\n",
      "Processing node # 1450\n",
      "Processing node # 1460\n",
      "Processing node # 1470\n",
      "Processing node # 1480\n",
      "Processing node # 1490\n",
      "Processing node # 1500\n",
      "Processing node # 1510\n",
      "Processing node # 1520\n",
      "Processing node # 1530\n",
      "Processing node # 1540\n",
      "Processing node # 1550\n",
      "Processing node # 1560\n",
      "Processing node # 1570\n",
      "Processing node # 1580\n",
      "Processing node # 1590\n",
      "Processing node # 1600\n",
      "Processing node # 1610\n",
      "Processing node # 1620\n",
      "Processing node # 1630\n",
      "Processing node # 1640\n",
      "Processing node # 1650\n",
      "Processing node # 1660\n",
      "Processing node # 1670\n",
      "Processing node # 1680\n",
      "Processing node # 1690\n",
      "Processing node # 1700\n",
      "Processing node # 1710\n",
      "Processing node # 1720\n",
      "Processing node # 1730\n",
      "Processing node # 1740\n",
      "Processing node # 1750\n",
      "Processing node # 1760\n",
      "Processing node # 1770\n",
      "Processing node # 1780\n",
      "Processing node # 1790\n",
      "Processing node # 1800\n",
      "Processing node # 1810\n",
      "Processing node # 1820\n",
      "Processing node # 1830\n",
      "Processing node # 1840\n",
      "Processing node # 1850\n",
      "Processing node # 1860\n",
      "Processing node # 1870\n",
      "Processing node # 1880\n",
      "Processing node # 1890\n",
      "Processing node # 1900\n",
      "Processing node # 1910\n",
      "Processing node # 1920\n",
      "Processing node # 1930\n",
      "Processing node # 1940\n",
      "Processing node # 1950\n",
      "Processing node # 1960\n",
      "Processing node # 1970\n",
      "Processing node # 1980\n",
      "Processing node # 1990\n",
      "Processing node # 2000\n",
      "Processing node # 2010\n",
      "Processing node # 2020\n",
      "Processing node # 2030\n",
      "Processing node # 2040\n",
      "Processing node # 2050\n",
      "Processing node # 2060\n",
      "Processing node # 2070\n",
      "Processing node # 2080\n",
      "Processing node # 2090\n",
      "Processing node # 2100\n"
     ]
    }
   ],
   "source": [
    "matchingMtx = []\n",
    "mpPool = mp.Pool(processes=2)\n",
    "for i, s in enumerate(nodeCatSet):\n",
    "#     if i < len(catName): continue\n",
    "    matchingMtx.append(matchingResult(s, mpPool))\n",
    "    if i % 10 == 0:\n",
    "        print 'Processing node #',i\n",
    "mpPool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputFileName = 'model/hcTree1_matching.pickle.gz'\n",
    "with gzip.open(outputFileName, 'wb') as fout:\n",
    "    pickle.dump((matchingMtx, descList), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2099 [(13, 0.1878392814615142), (39, 0.20250548276190292), (226, 0.2341227006916385)] (111, 387.7966897485003, 2090, 2078, 1.355638759831728)\n",
      "2100 [(31, 0.09454327942168135), (3, 0.11754990830052049), (30, 0.12877143423798257)] (178, 607.6720768606814, 2094, 2081, 1.4489559291407494)\n",
      "2101 [(1, 0.05069109038694025), (19, 0.1249572038462993), (38, 0.13617335809629266)] (338, 1183.4705633776248, 2097, 2095, 1.4828614263031925)\n",
      "2102 [(2, 0.14042195510470953), (75, 0.1663088977197052), (28, 0.16874270898014262)] (158, 545.3158629555846, 2093, 2091, 1.5192155034762984)\n",
      "2103 [(13, 0.13829276925021142), (4, 0.17283897065962012), (39, 0.20444265859002345)] (213, 738.3682339170988, 2099, 2096, 1.6038876597063956)\n",
      "2104 [(1, 0.06848487911946285), (0, 0.14337959848083326), (19, 0.14865818149487703)] (406, 1407.5512860989402, 2101, 2092, 1.646253936452292)\n",
      "2105 [(31, 0.06271856656553661), (17, 0.11360435737091924), (215, 0.11511002789850311)] (278, 941.8621685482683, 2100, 2098, 1.6657312592580618)\n",
      "2106 [(4, 0.08363667502715288), (13, 0.08398993697475038), (36, 0.15706783495043478)] (371, 1283.6840968726833, 2103, 2102, 1.8191506936152089)\n",
      "2107 [(25, 0.07966348573123101), (1, 0.09032002842156275), (138, 0.09153434173790137)] (684, 2349.4134546472087, 2105, 2104, 1.9317699686201735)\n",
      "2108 [(1, 0.05322849276214875), (4, 0.053734073785196984), (0, 0.05484211757695799)] (1055, 3633.097551519892, 2107, 2106, 2.1705007356239143)\n"
     ]
    }
   ],
   "source": [
    "for i, matches in enumerate(matchingMtx):\n",
    "    if len(matchingMtx) - i <= 10:\n",
    "        print i, sorted(enumerate(matches), key=lambda x:x[1])[:3], taxoTreeNodes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
